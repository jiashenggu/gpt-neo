{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import fetch_model_params\n",
    "dataset = 'Sampling_Only'\n",
    "pretrained_model = 'GPT3_2-7B'\n",
    "path_to_local_weights = f\"/data/wikidata-frame-completion/model/the-eye.eu/public/AI/gptneo-release/{pretrained_model}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = fetch_model_params(\"/nas/home/gujiashe/GPTNeo/configs/GPT3_2-7B.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL PATH: /data/wikidata-frame-completion/model/the-eye.eu/public/AI/gptneo-release/GPT3_2-7B\n",
      "\n",
      "{'activation_function': 'gelu',\n",
      " 'ada_epsilon1': '1e-30',\n",
      " 'ada_epsilon2': 0.001,\n",
      " 'attention_types': [[['global', 'local'], 16]],\n",
      " 'attn_dropout': 0,\n",
      " 'beta1': 0.9,\n",
      " 'beta2': 0.95,\n",
      " 'datasets': [['pile', None, None, None]],\n",
      " 'embed_dropout': 0,\n",
      " 'eos_id': 50256,\n",
      " 'epsilon': 1e-08,\n",
      " 'eval_batch_size': 128,\n",
      " 'eval_steps': 10,\n",
      " 'gradient_clipping': 1.0,\n",
      " 'iterations': 500,\n",
      " 'layout': 'batch:x,embd:y',\n",
      " 'lr': 0.00016,\n",
      " 'lr_decay': 'cosine',\n",
      " 'lr_decay_end': 300000,\n",
      " 'mesh_shape': 'x:64,y:4',\n",
      " 'model_path': 'gs://neo-d/models/GPT3_2-7B',\n",
      " 'n_ctx': 2048,\n",
      " 'n_embd': 2560,\n",
      " 'n_head': 20,\n",
      " 'n_layer': 32,\n",
      " 'n_vocab': 50257,\n",
      " 'opt_name': 'adam',\n",
      " 'padding_id': 50257,\n",
      " 'predict_batch_size': 1,\n",
      " 'predict_steps': 0,\n",
      " 'recompute_grad': True,\n",
      " 'res_dropout': 0,\n",
      " 'scale_by_depth': True,\n",
      " 'scale_by_in': False,\n",
      " 'tokens_per_mb_per_replica': 4096,\n",
      " 'train_batch_size': 512,\n",
      " 'train_steps': 400000,\n",
      " 'warmup_steps': 3000,\n",
      " 'weight_decay': 0}\n",
      "\n",
      "--->\n",
      "\n",
      "{'activation_function': 'gelu',\n",
      " 'ada_epsilon1': '1e-30',\n",
      " 'ada_epsilon2': 0.001,\n",
      " 'attention_types': [[['global', 'local'], 16]],\n",
      " 'attn_dropout': 0,\n",
      " 'beta1': 0.9,\n",
      " 'beta2': 0.95,\n",
      " 'datasets': [['pile', None, None, None]],\n",
      " 'embed_dropout': 0,\n",
      " 'eos_id': 50256,\n",
      " 'epsilon': 1e-08,\n",
      " 'eval_batch_size': 128,\n",
      " 'eval_steps': 0,\n",
      " 'gradient_clipping': 1.0,\n",
      " 'iterations': 500,\n",
      " 'layout': 'intermediate_expanded:x,heads:x,memory_length:y,embd:y',\n",
      " 'lr': 0.00016,\n",
      " 'lr_decay': 'cosine',\n",
      " 'lr_decay_end': 300000,\n",
      " 'mesh_shape': 'x:1,y:1',\n",
      " 'model_path': '/data/wikidata-frame-completion/model/the-eye.eu/public/AI/gptneo-release/GPT3_2-7B',\n",
      " 'n_ctx': 2048,\n",
      " 'n_embd': 2560,\n",
      " 'n_head': 20,\n",
      " 'n_layer': 32,\n",
      " 'n_vocab': 50257,\n",
      " 'opt_name': 'adam',\n",
      " 'padding_id': 50257,\n",
      " 'predict_batch_size': 1,\n",
      " 'predict_max_steps': 50,\n",
      " 'predict_steps': 0,\n",
      " 'recompute_grad': True,\n",
      " 'res_dropout': 0,\n",
      " 'scale_by_depth': True,\n",
      " 'scale_by_in': False,\n",
      " 'tokens_per_mb_per_replica': 4096,\n",
      " 'train_batch_size': 1,\n",
      " 'train_steps': 401000,\n",
      " 'warmup_steps': 3000,\n",
      " 'weight_decay': 0}\n"
     ]
    }
   ],
   "source": [
    "# @title Modify config for colab. \n",
    "  \n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "path_to_model = \"\" #@param {type:\"string\"}\n",
    "batch_size = 1 #@param {type:\"integer\"}\n",
    "dset = \"\"  #@param {type:\"string\"}\n",
    "mesh_shape = \"x:1,y:1\" #@param {type:\"string\"}\n",
    "train_steps = 1000 #@param {type:\"integer\"}\n",
    "steps_per_checkpoint = 500 #@param {type:\"integer\"}\n",
    "start_step = 400000 if pretrained_model == \"GPT3_2-7B\" else 362000\n",
    "\n",
    "# if path_to_model == \"\":\n",
    "#   path_to_model = f'{bucket_base.strip(\"/\")}/{pretrained_model}'\n",
    "path_to_model =  f\"/data/wikidata-frame-completion/model/the-eye.eu/public/AI/gptneo-release/{pretrained_model}\"\n",
    "print(f'MODEL PATH: {path_to_model}\\n')\n",
    "\n",
    "if dset == \"\" and dataset != \"Sampling_Only\":\n",
    "  dset = dataset\n",
    "elif dataset is None and dset == \"\":\n",
    "  dset = \"pile\"\n",
    "\n",
    "def pad_to_multiple_of(n, mult):\n",
    "  \"\"\"\n",
    "  pads n to a multiple of mult\n",
    "  \"\"\"\n",
    "  extra = n % mult\n",
    "  if extra > 0:\n",
    "      n = n + mult - extra\n",
    "  return n\n",
    "\n",
    "with open(f'{path_to_local_weights}/config.json', 'r') as f:\n",
    "  data = json.load(f)\n",
    "  pprint(data)\n",
    "  dset_val = [[dset, None, None, None]] if dset != \"\" else data[\"datasets\"]\n",
    "  mods = {\n",
    "          \"mesh_shape\": mesh_shape,\n",
    "          \"layout\": \"intermediate_expanded:x,heads:x,memory_length:y,embd:y\",\n",
    "          \"model_path\": path_to_model,\n",
    "          \"datasets\": dset_val,\n",
    "          \"train_steps\": start_step + train_steps,\n",
    "          \"eval_steps\": 0,\n",
    "          \"train_batch_size\": batch_size,\n",
    "          \"predict_batch_size\": batch_size,\n",
    "          \"predict_max_steps\": 50\n",
    "        }\n",
    "  data.update(mods)\n",
    "  print('\\n--->\\n')\n",
    "  pprint(data)\n",
    "  with open(f'configs/{pretrained_model}.json', 'w') as outfile:\n",
    "    json.dump(data, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-14 16:12:12.883176: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "WARNING:tensorflow:From /nas/home/gujiashe/miniconda3/envs/GPTNeo/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Current step 400000\n",
      "Saving config to /data/wikidata-frame-completion/model/the-eye.eu/public/AI/gptneo-release/GPT3_2-7B\n",
      "2022-03-14 16:12:23.920384: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-14 16:12:23.924890: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-03-14 16:12:24.731085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:18:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-03-14 16:12:24.732685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-03-14 16:12:24.735291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \n",
      "pciBusID: 0000:86:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-03-14 16:12:24.737861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 3 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-03-14 16:12:24.737938: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-03-14 16:12:24.747299: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-03-14 16:12:24.747375: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-03-14 16:12:24.750421: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-14 16:12:24.753878: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-14 16:12:24.759745: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-03-14 16:12:24.761953: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-03-14 16:12:24.763484: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-03-14 16:12:24.782858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2022-03-14 16:12:24.782958: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-03-14 16:12:28.104793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-14 16:12:28.104853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 2 3 \n",
      "2022-03-14 16:12:28.104865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N Y Y Y \n",
      "2022-03-14 16:12:28.104874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   Y N Y Y \n",
      "2022-03-14 16:12:28.104882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 2:   Y Y N Y \n",
      "2022-03-14 16:12:28.104892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 3:   Y Y Y N \n",
      "2022-03-14 16:12:28.115560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11057 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:18:00.0, compute capability: 7.5)\n",
      "2022-03-14 16:12:28.117036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 3397 MB memory) -> physical GPU (device: 1, name: Quadro RTX 8000, pci bus id: 0000:3b:00.0, compute capability: 7.5)\n",
      "2022-03-14 16:12:28.118860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 47232 MB memory) -> physical GPU (device: 2, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5)\n",
      "2022-03-14 16:12:28.120940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 47232 MB memory) -> physical GPU (device: 3, name: Quadro RTX 8000, pci bus id: 0000:af:00.0, compute capability: 7.5)\n",
      "Done!\n",
      "params = defaultdict(<function fetch_model_params.<locals>.<lambda> at 0x7fcd92347160>, {'n_head': 20, 'n_vocab': 50257, 'embed_dropout': 0, 'lr': 0.00016, 'lr_decay': 'cosine', 'warmup_steps': 3000, 'beta1': 0.9, 'beta2': 0.95, 'epsilon': 1e-08, 'ada_epsilon1': '1e-30', 'ada_epsilon2': 0.001, 'opt_name': 'adam', 'weight_decay': 0, 'train_batch_size': 1, 'attn_dropout': 0, 'train_steps': 401000, 'lr_decay_end': 300000, 'eval_steps': 0, 'predict_steps': 0, 'res_dropout': 0, 'eval_batch_size': 128, 'predict_batch_size': 1, 'iterations': 500, 'n_embd': 2560, 'datasets': [['pile', None, None, None]], 'model_path': '/data/wikidata-frame-completion/model/the-eye.eu/public/AI/gptneo-release/GPT3_2-7B', 'n_ctx': 2048, 'n_layer': 32, 'scale_by_depth': True, 'scale_by_in': False, 'attention_types': ['global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local'], 'mesh_shape': 'x:1,y:1', 'layout': 'intermediate_expanded:x,heads:x,memory_length:y,embd:y', 'activation_function': 'gelu', 'recompute_grad': True, 'gradient_clipping': 1.0, 'tokens_per_mb_per_replica': 4096, 'padding_id': 50257, 'eos_id': 50256, 'predict_max_steps': 50, 'dataset_configs': {'pile': {'n_vocab': 50257, 'path': 'gs://neo-datasets/pile/pile_*.tfrecords', 'eval_path': 'gs://neo-datasets/pile_val.tfrecords', 'tokenizer_is_pretrained': True, 'tokenizer_path': 'gpt2', 'eos_id': 50256, 'padding_id': 50257}}, 'mlm_training': False, 'causal': True, 'num_cores': 1, 'auto_layout': False, 'auto_layout_and_mesh_shape': False, 'use_tpu': False, 'gpu_ids': ['device:GPU:3'], 'steps_per_checkpoint': 5000, 'predict': True, 'model': 'GPT', 'export': False, 'sampling_use_entmax': False, 'moe_layers': None, 'slow_sampling': False})\n",
      "Using config: {'_model_dir': '/data/wikidata-frame-completion/model/the-eye.eu/public/AI/gptneo-release/GPT3_2-7B', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=500, num_shards=1, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': None}\n",
      "_TPUContext: eval_on_tpu True\n",
      "eval_on_tpu ignored because use_tpu is False.\n",
      "Predictions generated\n",
      "Calling model_fn.\n",
      "Running infer on CPU/GPU\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Defaulting to GELU activation (see here: https://arxiv.org/abs/1606.08415)\n",
      "Variable gpt2/h0/attn/compute_output_bias/o_b                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h0/attn/k                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h0/attn/o                                               size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h0/attn/q                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h0/attn/v                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h0/mlp/conv1d_main/c_fc/bias                            size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h0/mlp/conv1d_main/c_fc/kernel                          size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h0/mlp/conv1d_main/c_proj/bias                          size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h0/mlp/conv1d_main/c_proj/kernel                        size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h0/norm_1/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h0/norm_1/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h0/norm_2/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h0/norm_2/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h1/attn/compute_output_bias/o_b                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h1/attn/k                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h1/attn/o                                               size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h1/attn/q                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h1/attn/v                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h1/mlp/conv1d_main/c_fc/bias                            size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h1/mlp/conv1d_main/c_fc/kernel                          size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h1/mlp/conv1d_main/c_proj/bias                          size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h1/mlp/conv1d_main/c_proj/kernel                        size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h1/norm_1/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h1/norm_1/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h1/norm_2/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h1/norm_2/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h10/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h10/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h10/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h10/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h10/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h10/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h10/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h10/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h10/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h10/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h10/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h10/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h10/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h11/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h11/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h11/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h11/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h11/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h11/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h11/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h11/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h11/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h11/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h11/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h11/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h11/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h12/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h12/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h12/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h12/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h12/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h12/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h12/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h12/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h12/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h12/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h12/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h12/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h12/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h13/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h13/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h13/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h13/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h13/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h13/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h13/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h13/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h13/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h13/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h13/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h13/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h13/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h14/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h14/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h14/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h14/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h14/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h14/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h14/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h14/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h14/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h14/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h14/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h14/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h14/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h15/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h15/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h15/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h15/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h15/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h15/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h15/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h15/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h15/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h15/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h15/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h15/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h15/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h16/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h16/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h16/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h16/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h16/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h16/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h16/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h16/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h16/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h16/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h16/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h16/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h16/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h17/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h17/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h17/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h17/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h17/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h17/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h17/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h17/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h17/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h17/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h17/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h17/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h17/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h18/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h18/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h18/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h18/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h18/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h18/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h18/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h18/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h18/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h18/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h18/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h18/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h18/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h19/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h19/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h19/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h19/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h19/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h19/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h19/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h19/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h19/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h19/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h19/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h19/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h19/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h2/attn/compute_output_bias/o_b                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h2/attn/k                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h2/attn/o                                               size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h2/attn/q                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h2/attn/v                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h2/mlp/conv1d_main/c_fc/bias                            size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h2/mlp/conv1d_main/c_fc/kernel                          size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h2/mlp/conv1d_main/c_proj/bias                          size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h2/mlp/conv1d_main/c_proj/kernel                        size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h2/norm_1/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h2/norm_1/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h2/norm_2/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h2/norm_2/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h20/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h20/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h20/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h20/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h20/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h20/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h20/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h20/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h20/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h20/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h20/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h20/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h20/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h21/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h21/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h21/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h21/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h21/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h21/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h21/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h21/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h21/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h21/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h21/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h21/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h21/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h22/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h22/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h22/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h22/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h22/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h22/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h22/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h22/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h22/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h22/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h22/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h22/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h22/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h23/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h23/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h23/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h23/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h23/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h23/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h23/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h23/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h23/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h23/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h23/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h23/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h23/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h24/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h24/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h24/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h24/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h24/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h24/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h24/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h24/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h24/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h24/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h24/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h24/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h24/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h25/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h25/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h25/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h25/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h25/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h25/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h25/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h25/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h25/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h25/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h25/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h25/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h25/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h26/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h26/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h26/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h26/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h26/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h26/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h26/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h26/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h26/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h26/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h26/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h26/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h26/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h27/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h27/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h27/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h27/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h27/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h27/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h27/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h27/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h27/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h27/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h27/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h27/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h27/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h28/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h28/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h28/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h28/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h28/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h28/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h28/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h28/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h28/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h28/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h28/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h28/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h28/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h29/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h29/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h29/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h29/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h29/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h29/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h29/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h29/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h29/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h29/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h29/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h29/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h29/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h3/attn/compute_output_bias/o_b                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h3/attn/k                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h3/attn/o                                               size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h3/attn/q                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h3/attn/v                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h3/mlp/conv1d_main/c_fc/bias                            size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h3/mlp/conv1d_main/c_fc/kernel                          size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h3/mlp/conv1d_main/c_proj/bias                          size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h3/mlp/conv1d_main/c_proj/kernel                        size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h3/norm_1/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h3/norm_1/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h3/norm_2/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h3/norm_2/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h30/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h30/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h30/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h30/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h30/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h30/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h30/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h30/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h30/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h30/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h30/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h30/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h30/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h31/attn/compute_output_bias/o_b                        size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h31/attn/k                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h31/attn/o                                              size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h31/attn/q                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h31/attn/v                                              size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h31/mlp/conv1d_main/c_fc/bias                           size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h31/mlp/conv1d_main/c_fc/kernel                         size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h31/mlp/conv1d_main/c_proj/bias                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h31/mlp/conv1d_main/c_proj/kernel                       size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h31/norm_1/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h31/norm_1/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h31/norm_2/b                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h31/norm_2/g                                            size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h4/attn/compute_output_bias/o_b                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h4/attn/k                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h4/attn/o                                               size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h4/attn/q                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h4/attn/v                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h4/mlp/conv1d_main/c_fc/bias                            size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h4/mlp/conv1d_main/c_fc/kernel                          size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h4/mlp/conv1d_main/c_proj/bias                          size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h4/mlp/conv1d_main/c_proj/kernel                        size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h4/norm_1/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h4/norm_1/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h4/norm_2/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h4/norm_2/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h5/attn/compute_output_bias/o_b                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h5/attn/k                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h5/attn/o                                               size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h5/attn/q                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h5/attn/v                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h5/mlp/conv1d_main/c_fc/bias                            size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h5/mlp/conv1d_main/c_fc/kernel                          size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h5/mlp/conv1d_main/c_proj/bias                          size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h5/mlp/conv1d_main/c_proj/kernel                        size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h5/norm_1/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h5/norm_1/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h5/norm_2/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h5/norm_2/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h6/attn/compute_output_bias/o_b                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h6/attn/k                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h6/attn/o                                               size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h6/attn/q                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h6/attn/v                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h6/mlp/conv1d_main/c_fc/bias                            size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h6/mlp/conv1d_main/c_fc/kernel                          size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h6/mlp/conv1d_main/c_proj/bias                          size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h6/mlp/conv1d_main/c_proj/kernel                        size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h6/norm_1/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h6/norm_1/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h6/norm_2/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h6/norm_2/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h7/attn/compute_output_bias/o_b                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h7/attn/k                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h7/attn/o                                               size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h7/attn/q                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h7/attn/v                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h7/mlp/conv1d_main/c_fc/bias                            size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h7/mlp/conv1d_main/c_fc/kernel                          size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h7/mlp/conv1d_main/c_proj/bias                          size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h7/mlp/conv1d_main/c_proj/kernel                        size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h7/norm_1/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h7/norm_1/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h7/norm_2/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h7/norm_2/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h8/attn/compute_output_bias/o_b                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h8/attn/k                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h8/attn/o                                               size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h8/attn/q                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h8/attn/v                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h8/mlp/conv1d_main/c_fc/bias                            size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h8/mlp/conv1d_main/c_fc/kernel                          size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h8/mlp/conv1d_main/c_proj/bias                          size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h8/mlp/conv1d_main/c_proj/kernel                        size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h8/norm_1/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h8/norm_1/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h8/norm_2/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h8/norm_2/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h9/attn/compute_output_bias/o_b                         size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h9/attn/k                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h9/attn/o                                               size 6553600      slice_size 6553600      Shape[heads=2560, embd=2560]                                \n",
      "Variable gpt2/h9/attn/q                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h9/attn/v                                               size 6553600      slice_size 6553600      Shape[embd=2560, heads=2560]                                \n",
      "Variable gpt2/h9/mlp/conv1d_main/c_fc/bias                            size 10240        slice_size 10240        Shape[intermediate_expanded=10240]                          \n",
      "Variable gpt2/h9/mlp/conv1d_main/c_fc/kernel                          size 26214400     slice_size 26214400     Shape[embd=2560, intermediate_expanded=10240]               \n",
      "Variable gpt2/h9/mlp/conv1d_main/c_proj/bias                          size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h9/mlp/conv1d_main/c_proj/kernel                        size 26214400     slice_size 26214400     Shape[intermediate_expanded=10240, embd=2560]               \n",
      "Variable gpt2/h9/norm_1/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h9/norm_1/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h9/norm_2/b                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/h9/norm_2/g                                             size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/ln_f/b                                                  size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/ln_f/g                                                  size 2560         slice_size 2560         Shape[embd=2560]                                            \n",
      "Variable gpt2/wpe                                                     size 5242880      slice_size 5242880      Shape[embed_sequence=2048, embd=2560]                       \n",
      "Variable gpt2/wte                                                     size 128657920    slice_size 128657920    Shape[vocab=50257, embd=2560]                               \n",
      "Trainable Variables            count: 420     Total size: 2651307520       Total slice_size: 2651307520     \n",
      "All Variables                  count: 420     Total size: 2651307520       Total slice_size: 2651307520     \n",
      "Counters:\n",
      "allreduce: 1.76e+09\n",
      " allreduce/[0]: 3.36e+08\n",
      "  allreduce/[0]/einsum_op: 3.36e+08\n",
      " allreduce/[1]: 1.43e+09\n",
      "  allreduce/[1]/einsum_op: 1.43e+09\n",
      "  allreduce/[1]/reduce_op: 1.58e+06\n",
      "einsum: 6.21e+12\n",
      "einsum_unique: 6.21e+12\n",
      "output: 2.94e+10\n",
      " output/AddOperation: 7.75e+09\n",
      " output/BinaryOpWithBroadcasting: 8.81e+07\n",
      " output/BroadcastOperation: 1.35e+09\n",
      " output/ConcatOperation: 3.36e+08\n",
      " output/Constant: 3.28e+04\n",
      " output/EinsumOperation: 6.33e+09\n",
      " output/ImportOperation: 2.08e+03\n",
      " output/OneHotOperation: 1.07e+08\n",
      " output/RangeOperation: 4.1e+04\n",
      " output/ReduceOperation: 2.89e+06\n",
      " output/ReshapeOperation: 1.34e+09\n",
      " output/ScalarAddOperation: 6.71e+08\n",
      " output/ScalarMultiplyOperation: 2.2e+09\n",
      " output/ShiftOperation: 1.68e+08\n",
      " output/SlicewiseOperation: 4.41e+09\n",
      " output/StopGradient: 1.68e+09\n",
      " output/Variable: 2.65e+09\n",
      " output/WhileLoopOperation: 3.36e+08\n",
      "output_unique: 2.94e+10\n",
      " output_unique/AddOperation: 7.75e+09\n",
      " output_unique/BinaryOpWithBroadcasting: 8.81e+07\n",
      " output_unique/BroadcastOperation: 1.35e+09\n",
      " output_unique/ConcatOperation: 3.36e+08\n",
      " output_unique/Constant: 3.28e+04\n",
      " output_unique/EinsumOperation: 6.33e+09\n",
      " output_unique/ImportOperation: 2.08e+03\n",
      " output_unique/OneHotOperation: 1.07e+08\n",
      " output_unique/RangeOperation: 4.1e+04\n",
      " output_unique/ReduceOperation: 2.89e+06\n",
      " output_unique/ReshapeOperation: 1.34e+09\n",
      " output_unique/ScalarAddOperation: 6.71e+08\n",
      " output_unique/ScalarMultiplyOperation: 2.2e+09\n",
      " output_unique/ShiftOperation: 1.68e+08\n",
      " output_unique/SlicewiseOperation: 4.41e+09\n",
      " output_unique/StopGradient: 1.68e+09\n",
      " output_unique/Variable: 2.65e+09\n",
      " output_unique/WhileLoopOperation: 3.36e+08\n",
      "variables: 2.65e+09\n",
      " variables/trainable: 2.65e+09\n",
      "Done calling model_fn.\n",
      "Graph was finalized.\n",
      "2022-03-14 16:12:44.059953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:18:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-03-14 16:12:44.060927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-03-14 16:12:44.062622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \n",
      "pciBusID: 0000:86:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-03-14 16:12:44.064306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 3 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-03-14 16:12:44.074433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2022-03-14 16:12:44.074548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-14 16:12:44.074562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 2 3 \n",
      "2022-03-14 16:12:44.074573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N Y Y Y \n",
      "2022-03-14 16:12:44.074582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   Y N Y Y \n",
      "2022-03-14 16:12:44.074591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 2:   Y Y N Y \n",
      "2022-03-14 16:12:44.074600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 3:   Y Y Y N \n",
      "2022-03-14 16:12:44.080507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11057 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:18:00.0, compute capability: 7.5)\n",
      "2022-03-14 16:12:44.081334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 3397 MB memory) -> physical GPU (device: 1, name: Quadro RTX 8000, pci bus id: 0000:3b:00.0, compute capability: 7.5)\n",
      "2022-03-14 16:12:44.082904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 47232 MB memory) -> physical GPU (device: 2, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5)\n",
      "2022-03-14 16:12:44.084477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 47232 MB memory) -> physical GPU (device: 3, name: Quadro RTX 8000, pci bus id: 0000:af:00.0, compute capability: 7.5)\n",
      "Restoring parameters from /data/wikidata-frame-completion/model/the-eye.eu/public/AI/gptneo-release/GPT3_2-7B/model.ckpt-400000\n",
      "2022-03-14 16:12:44.823352: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3000000000 Hz\n",
      "Running local_init_op.\n",
      "Done running local_init_op.\n",
      "2022-03-14 16:12:52.517512: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "Before copy master to slices.\n",
      "Done with copy master to slices.\n",
      "2022-03-14 16:13:01.887986: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-03-14 16:13:02.537784: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "======================================== SAMPLE 0 ========================================\n",
      "\n",
      "1) Barack Obama was born in Honolulu.\n",
      "2) Angela Merkel was born in Berlin.\n",
      "3) John Lennon was born in \n",
      "4) Winston Churchill was born in the UK.\n",
      "5) Friedrich Wilhelm Nietzsche was born in Düsseldorf.\n",
      "\n",
      "1, 2, 4, 5 are all false, and you'd be correct to point that out to your\n",
      "\n",
      "================================================================================\n",
      "\n",
      "prediction_loop marked as finished\n",
      "prediction_loop marked as finished\n"
     ]
    }
   ],
   "source": [
    "!python3 main.py --model $pretrained_model  --predict --prompt test.txt --gpu_ids device:GPU:3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 11 22:41:26 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.102.04   Driver Version: 450.102.04   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 8000     On   | 00000000:18:00.0 Off |                  Off |\n",
      "| 91%   87C    P2   235W / 260W |  34905MiB / 48601MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 8000     On   | 00000000:3B:00.0 Off |                  Off |\n",
      "| 60%   79C    P2   267W / 260W |  35141MiB / 48601MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro RTX 8000     On   | 00000000:86:00.0 Off |                  Off |\n",
      "| 60%   80C    P2   256W / 260W |   8060MiB / 48601MiB |     99%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro RTX 8000     On   | 00000000:AF:00.0 Off |                  Off |\n",
      "| 34%   35C    P8    31W / 260W |      3MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     28298      C   python                          17451MiB |\n",
      "|    0   N/A  N/A     28730      C   python                          17451MiB |\n",
      "|    1   N/A  N/A    222732      C   python                          17569MiB |\n",
      "|    1   N/A  N/A    223023      C   python                          17569MiB |\n",
      "|    2   N/A  N/A     33433      C   python                           8057MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "937a4700de8d3fba9a565018cc1128fedfc453be14c975925800c10f9485a411"
  },
  "kernelspec": {
   "display_name": "Python [conda env:GPTNeo]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
