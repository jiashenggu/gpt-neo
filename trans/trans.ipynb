{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPTNeoForCausalLM\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")\n",
    "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 2560)\n",
       "    (wpe): Embedding(2048, 2560)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (25): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (26): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (27): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (28): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (29): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (30): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (31): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanReciprocalRank:\n",
    "    def __init__(self):\n",
    "        self._sum = 0.0\n",
    "        self._n = 0.0\n",
    "\n",
    "    def __call__(self, predictions, labels):\n",
    "        # Flatten\n",
    "        labels = labels.view(-1)\n",
    "        \n",
    "        predictions = predictions.view(labels.shape[0], -1)\n",
    "\n",
    "        \n",
    "        # MRR computation\n",
    "        label_scores = predictions.gather(-1, labels.unsqueeze(-1))\n",
    "        rank = predictions.ge(label_scores).sum(1).float()\n",
    "        # print(rank)\n",
    "        reciprocal_rank = 1 / rank\n",
    "        self._sum += (reciprocal_rank).sum().item()\n",
    "        self._n += len(labels)\n",
    "\n",
    "    def get_metric(self, reset=False):\n",
    "        mrr = self._sum / (self._n + 1e-13)\n",
    "        if reset:\n",
    "            self.reset()\n",
    "        return mrr\n",
    "    def reset(self):\n",
    "        self._sum = 0.0\n",
    "        self._n = 0.0\n",
    "class Hits:\n",
    "    def __init__(self, topn):\n",
    "        self.topn = topn\n",
    "        self._sum = 0.0\n",
    "        self._n = 0.0\n",
    "\n",
    "    def __call__(self, predictions, labels):\n",
    "        # Flatten\n",
    "        labels = labels.view(-1)\n",
    "\n",
    "        predictions = predictions.view(labels.shape[0], -1)\n",
    "\n",
    "\n",
    "        # MRR computation\n",
    "        label_scores = predictions.gather(-1, labels.unsqueeze(-1))\n",
    "        rank = predictions.ge(label_scores).sum(1).float()\n",
    "        # reciprocal_rank = 1 / rank\n",
    "        score = rank.le(self.topn).float()\n",
    "        self._sum += (score).sum().item()\n",
    "        self._n += len(labels)\n",
    "\n",
    "    def get_metric(self, reset=False):\n",
    "        hits = self._sum / (self._n + 1e-13)\n",
    "        if reset:\n",
    "            self.reset()\n",
    "        return hits\n",
    "\n",
    "    def reset(self):\n",
    "        self._sum = 0.0\n",
    "        self._n = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import csv\n",
    "s_list = []\n",
    "birth_property = \"place\"\n",
    "with open('birth_table1.tsv', 'r') as t:\n",
    "    i = 0\n",
    "    # sentences_birth = open(\"sentences_birth.tsv\", \"w\")\n",
    "    # tsv_writer = csv.writer(sentences_birth, delimiter='\\t')\n",
    "\n",
    "    for line in t:\n",
    "        i+=1\n",
    "        if i==1:\n",
    "            continue\n",
    "        \n",
    "        person, mother, place, date = line.split('\\t')\n",
    "        if len(mother) == 0:\n",
    "            continue\n",
    "        def process(raw):\n",
    "            raw = raw.split(\"@\")\n",
    "            content, lang = raw\n",
    "            content = content.strip(\"''\").split()\n",
    "            return content, lang\n",
    "\n",
    "        person, lang = process(person)\n",
    "        if lang != \"en\":\n",
    "            continue\n",
    "        mother, lang = process(mother)\n",
    "        if lang != \"en\":\n",
    "            continue        \n",
    "        place, lang = process(place)\n",
    "        if lang != \"en\":\n",
    "            continue\n",
    "        \n",
    "        date = date.split('T')[0][1:]\n",
    "        year, month, day = date.split('-')\n",
    "        year = int(year)\n",
    "        month = int(month)\n",
    "        day = int(day)\n",
    "        d = datetime.date(year, month, day)\n",
    "        date = d.strftime(\"%d %B %Y\").split()\n",
    "\n",
    "        # sentence = mother + [\"gave\", \"birth\", \"to\"] + person + [\"on\"] + date + ['.']\n",
    "        # sentence = \" \".join(sentence)\n",
    "        sentence = \"\"\n",
    "        expect = \"\"\n",
    "        if birth_property == \"place\":\n",
    "            inference = person + [\"was\", \"born\", \"in\"] + place + ['.']\n",
    "            expect = place\n",
    "        elif birth_property == \"mother\":\n",
    "            inference = person + [\"'s\", \"mother\"] + [\"is\"] + mother + ['.']\n",
    "            expect = mother\n",
    "        elif birth_property == \"person\":\n",
    "            inference = mother + [\"gave\", \"birth\", \"to\"] + person + ['.']\n",
    "            expect = person\n",
    "        elif birth_property == \"date\":\n",
    "            inference = mother + [\"gave\", \"birth\", \"to\"] + person + [\"on\"] + date +['.']\n",
    "            expect = date\n",
    "        inference = \" \".join(inference)\n",
    "\n",
    "        s_expect = \" \".join(expect)\n",
    "        s_list.append(\"\\t\".join([sentence + '\\n' + inference, s_expect]))\n",
    "        # print(\"person: \", person,  \"mother: \", mother, \"place: \", place, \"date: \", date, len(place), len(date))\n",
    "        # “[MOTHER] gave birth to [PERSON] at [PLACE] on [DATE]” \n",
    "\n",
    "        # idx = 0\n",
    "        # spans = []\n",
    "        # spans.append([idx, idx + len(mother) - 1])\n",
    "        # idx+=len(mother) + 3\n",
    "        # spans.append([idx, idx + len(person) - 1])\n",
    "        # idx+=len(person) + 1\n",
    "        # spans.append([idx, idx + len(place) - 1])\n",
    "        # idx+=len(place) + 1\n",
    "\n",
    "        # date = date.split('T')[0][1:]\n",
    "        # year, month, day = date.split('-')\n",
    "        # year = int(year)\n",
    "        # month = int(month)\n",
    "        # day = int(day)\n",
    "        # d = datetime.date(year, month, day)\n",
    "        # date = d.strftime(\"%d %B %Y\").split()\n",
    "        # spans.append([idx, idx + 2])\n",
    "        \n",
    "        # s = mother + [\"gave\", \"birth\", \"to\"] + person + [\"at\"] + place + [\"on\"] + date + [\".\"]\n",
    "        # s = \" \".join(s)\n",
    "        # for span in spans:\n",
    "        #     tsv_writer.writerow([str(span[0]) + \" \" +  str(span[1])] + [s])\n",
    "        # print(spans)\n",
    "        # print(s)\n",
    "        # if i>10:\n",
    "        #     breaks\n",
    "    # sentences_birth.close()\n",
    "    # print(i)\n",
    "s_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:09<00:00, 14.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr:  0.11333945449814968\n",
      "hits@1:  0.07814693495554516\n",
      "hits@10:  0.1736078614880674\n",
      "hits@50:  0.2798315395414132\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "sample_num = 6\n",
    "\n",
    "\n",
    "spreadsheet_gptneo = open(birth_property+\"_spreadsheet_gptneo.tsv\", \"w\")\n",
    "tsv_writer = csv.writer(spreadsheet_gptneo, delimiter='\\t')\n",
    "mrr = MeanReciprocalRank()\n",
    "hits1 = Hits(1)\n",
    "hits10 = Hits(10)\n",
    "hits50 = Hits(50)\n",
    "\n",
    "total_ranks = []\n",
    "for _ in tqdm(range(1000)):\n",
    "    sample_ids = random.sample(range(len(s_list)), sample_num)\n",
    "    sample = \"\"\n",
    "    expect_final = \"\"\n",
    "    for i, sample_id in enumerate(sample_ids):\n",
    "        sentence, expect = s_list[sample_id].split('\\t')\n",
    "        sentence, inference = sentence.split('\\n')\n",
    "        len_expect = len(expect.split())\n",
    "        words = inference.split()\n",
    "        if i == sample_num-1:\n",
    "            expect_final = \" \"+expect\n",
    "            sentence = \"{})\".format(i+1) + sentence + '\\n' + \" \".join(words[:-1-len_expect])\n",
    "        else:\n",
    "            sentence = \"{})\".format(i+1) + sentence + '\\n' + \" \".join(words) + '\\n'\n",
    "        sample += sentence\n",
    "    # sample = \"1)Frances Ford Seymour gave birth to Jayne Seymour Fonda on 21 December 1937.\\\n",
    "    #         Jayne Seymour Fonda was born in New York City.\\\n",
    "    #         2)Sylvana Windsor, Countess of St Andrews gave birth to Amelia Sophia Theodora Mary Margaret Windsor on 24 August 1995.\\\n",
    "    #         Amelia Sophia Theodora Mary Margaret Windsor was born in Rosie Hospital.\\\n",
    "    #         3)Jane Hawker gave birth to Frances Anne Seymour on 14 August 1807.\\\n",
    "    #         Frances Anne Seymour was born in Plymouth.\\\n",
    "    #         4)Anne Mary Stephen gave birth to Albert Venn Dicey on 04 February 1835.\\\n",
    "    #         Albert Venn Dicey was born in Claybrooke Magna.\\\n",
    "    #         5)Edith Mawd Thomas gave birth to Richard Walter Jenkins on 10 November 1925.\\\n",
    "    #         Richard Walter Jenkins was born in Pontrhydyfen.\\\n",
    "    #         6)Katherine Chamberlain gave birth to Elizabeth Harman on 30 August 1906.\\\n",
    "    #         Elizabeth Harman was born in\"\n",
    "    # expect_final = \" London\"\n",
    "    # len_expect = len(expect_final.split())\n",
    "\n",
    "    # input_ids = len(tokenizer.tokenize(sample))\n",
    "    # generated_text = generator(sample, do_sample=True, max_length=input_ids+5)[0][\"generated_text\"]\n",
    "    input_ids = tokenizer(sample, return_tensors=\"pt\").input_ids\n",
    "    input_ids = input_ids.to(device)\n",
    "\n",
    "    expect_ids = tokenizer(expect_final, return_tensors=\"pt\").input_ids\n",
    "    expect_ids = expect_ids.to(device)\n",
    "    max_new_tokens = expect_ids.shape[1]\n",
    "\n",
    "\n",
    "    gen_output = model.generate(\n",
    "    input_ids,\n",
    "    # do_sample=True,\n",
    "    # temperature=0.9,\n",
    "    max_new_tokens = max_new_tokens,\n",
    "    # max_length = 100,\n",
    "    return_dict_in_generate = True,\n",
    "    output_scores = True,\n",
    "    pad_token_id = model.config.eos_token_id\n",
    ")\n",
    "    gen_tokens = gen_output.sequences\n",
    "    gen_scores = gen_output.scores\n",
    "    gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
    "    \n",
    "    gen_scores = torch.stack(list(gen_scores), dim=0).squeeze(1)\n",
    "\n",
    "    mrr(gen_scores, expect_ids)\n",
    "    hits1(gen_scores, expect_ids)\n",
    "    hits10(gen_scores, expect_ids)\n",
    "    hits50(gen_scores, expect_ids)\n",
    "    \n",
    "\n",
    "    ranks = torch.argsort(gen_scores, dim = 1, descending=True)\n",
    "    ranks = torch.argsort(ranks, dim = 1)\n",
    "    gen_ranks = [ranks[i][id].item() for i, id in enumerate(expect_ids[0])]\n",
    "    # print(expect_final)\n",
    "    # print(expect_ids)\n",
    "    # print(len_expect, max_new_tokens)\n",
    "    \n",
    "    expect_generate = \" \".join(gen_text.split()[-len_expect:])\n",
    "    # expect_generate = gen_text.split(\"was born in\")[-1]\n",
    "\n",
    "    total_ranks += gen_ranks\n",
    "    gen_ranks = list(map(str, gen_ranks))\n",
    "    gen_ranks = \",\".join(gen_ranks)\n",
    "    # break\n",
    "\n",
    "    # print([gen_text, expect_final, expect_generate, gen_ranks])\n",
    "    # print(torch.argmax(gen_scores, dim = 1))\n",
    "\n",
    "    tsv_writer.writerow([gen_text, expect_final, expect_generate, gen_ranks])\n",
    "    # break\n",
    "spreadsheet_gptneo.close()\n",
    "\n",
    "print(\"mrr: \", mrr.get_metric())\n",
    "print(\"hits@1: \", hits1.get_metric())\n",
    "print(\"hits@10: \", hits10.get_metric())\n",
    "print(\"hits@50: \", hits50.get_metric())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)\n",
      "Sarah Elizabeth Huckabee was born in Hope .\n",
      "2)\n",
      "Angus Fraser James Gunn was born in Norwich .\n",
      "3)\n",
      "Booker Taliaferro Washington was born in Hale\\'s Ford .\n",
      "4)\n",
      "Tulip Rizwana Siddiq was born in Mitcham .\n",
      "5)\n",
      "Michael Herbert Rudolf Knatchbull was born in London .\n",
      "6)\n",
      "Tudor St. John Harris was born in\n"
     ]
    }
   ],
   "source": [
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(total_ranks, bins = 100, range = [0, 100])\n",
    "plt.savefig(birth_property+'_gptneo.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = pipeline('text-generation', model=model, tokenizer=tokenizer, device = 6)\n",
    "# test_s = \"1) Barack Obama was born in Honolulu.\\n2) Angela Merkel was born in Berlin.\\n3) John Lennon was born in liverpool\\n4) Donald Trump was born in New York\\n5) Joe Biden was born in Pennsylvania\\n6) Clinton was born in\"\n",
    "# print(test_s)\n",
    "# len(tokenizer.tokenize(test_s))\n",
    "# generated = generator(test_s, do_sample=True, max_length=10)\n",
    "# print(generated[0][\"generated_text\"])\n",
    "\n",
    "# prompt = (\n",
    "#     \"In a shocking finding, scientists discovered a herd of unicorns living in a remote, \"\n",
    "#     \"previously unexplored valley, in the Andes Mountains. Even more surprising to the \"\n",
    "#     \"researchers was the fact that the unicorns spoke perfect English.\"\n",
    "# )\n",
    "# input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "# input_ids = input_ids.to(device)\n",
    "# gen_output = model.generate(\n",
    "#     input_ids,\n",
    "#     # do_sample=True,\n",
    "#     # temperature=0.9,\n",
    "#     max_length=60,\n",
    "#     return_dict_in_generate = True,\n",
    "#     output_scores = True\n",
    "# )\n",
    "# gen_tokens = gen_output.sequences\n",
    "# gen_scores = gen_output.scores\n",
    "# gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
    "# print(gen_text)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24e9b4ec3e5982e03e8718a00cb72022c31e89c1f9528f16f13627f3d4028efa"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
