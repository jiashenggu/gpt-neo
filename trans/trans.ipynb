{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPTNeoForCausalLM\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")\n",
    "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 2560)\n",
       "    (wpe): Embedding(2048, 2560)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (25): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (26): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (27): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (28): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (29): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (30): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (31): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:7')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = pipeline('text-generation', model=model, tokenizer=tokenizer, device = 6)\n",
    "# test_s = \"1) Barack Obama was born in Honolulu.\\n2) Angela Merkel was born in Berlin.\\n3) John Lennon was born in liverpool\\n4) Donald Trump was born in New York\\n5) Joe Biden was born in Pennsylvania\\n6) Clinton was born in\"\n",
    "# print(test_s)\n",
    "# len(tokenizer.tokenize(test_s))\n",
    "# generated = generator(test_s, do_sample=True, max_length=10)\n",
    "# print(generated[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import csv\n",
    "s_list = []\n",
    "with open('birth_table1.tsv', 'r') as t:\n",
    "    i = 0\n",
    "    # sentences_birth = open(\"sentences_birth.tsv\", \"w\")\n",
    "    # tsv_writer = csv.writer(sentences_birth, delimiter='\\t')\n",
    "\n",
    "    for line in t:\n",
    "        i+=1\n",
    "        if i==1:\n",
    "            continue\n",
    "        \n",
    "        person, mother, place, date = line.split('\\t')\n",
    "        if len(mother) == 0:\n",
    "            continue\n",
    "        def process(raw):\n",
    "            raw = raw.split(\"@\")\n",
    "            content, lang = raw\n",
    "            content = content.strip(\"''\").split()\n",
    "            return content, lang\n",
    "\n",
    "        person, lang = process(person)\n",
    "        if lang != \"en\":\n",
    "            continue\n",
    "        mother, lang = process(mother)\n",
    "        if lang != \"en\":\n",
    "            continue        \n",
    "        place, lang = process(place)\n",
    "        if lang != \"en\":\n",
    "            continue\n",
    "        \n",
    "        sentence = person + [\"was\", \"born\", \"in\"] + place + ['.']\n",
    "        sentence = \" \".join(sentence)\n",
    "        s_place = \" \".join(place)\n",
    "        s_list.append(\"\\t\".join([sentence, s_place]))\n",
    "        # print(\"person: \", person,  \"mother: \", mother, \"place: \", place, \"date: \", date, len(place), len(date))\n",
    "        # “[MOTHER] gave birth to [PERSON] at [PLACE] on [DATE]” \n",
    "\n",
    "        # idx = 0\n",
    "        # spans = []\n",
    "        # spans.append([idx, idx + len(mother) - 1])\n",
    "        # idx+=len(mother) + 3\n",
    "        # spans.append([idx, idx + len(person) - 1])\n",
    "        # idx+=len(person) + 1\n",
    "        # spans.append([idx, idx + len(place) - 1])\n",
    "        # idx+=len(place) + 1\n",
    "\n",
    "        # date = date.split('T')[0][1:]\n",
    "        # year, month, day = date.split('-')\n",
    "        # year = int(year)\n",
    "        # month = int(month)\n",
    "        # day = int(day)\n",
    "        # d = datetime.date(year, month, day)\n",
    "        # date = d.strftime(\"%d %B %Y\").split()\n",
    "        # spans.append([idx, idx + 2])\n",
    "        \n",
    "        # s = mother + [\"gave\", \"birth\", \"to\"] + person + [\"at\"] + place + [\"on\"] + date + [\".\"]\n",
    "        # s = \" \".join(s)\n",
    "        # for span in spans:\n",
    "        #     tsv_writer.writerow([str(span[0]) + \" \" +  str(span[1])] + [s])\n",
    "        # print(spans)\n",
    "        # print(s)\n",
    "        # if i>10:\n",
    "        #     breaks\n",
    "    # sentences_birth.close()\n",
    "    # print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = (\n",
    "#     \"In a shocking finding, scientists discovered a herd of unicorns living in a remote, \"\n",
    "#     \"previously unexplored valley, in the Andes Mountains. Even more surprising to the \"\n",
    "#     \"researchers was the fact that the unicorns spoke perfect English.\"\n",
    "# )\n",
    "# input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "# input_ids = input_ids.to(device)\n",
    "# gen_output = model.generate(\n",
    "#     input_ids,\n",
    "#     # do_sample=True,\n",
    "#     # temperature=0.9,\n",
    "#     max_length=60,\n",
    "#     return_dict_in_generate = True,\n",
    "#     output_scores = True\n",
    "# )\n",
    "# gen_tokens = gen_output.sequences\n",
    "# gen_scores = gen_output.scores\n",
    "# gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
    "# print(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanReciprocalRank:\n",
    "    def __init__(self):\n",
    "        self._sum = 0.0\n",
    "        self._n = 0.0\n",
    "\n",
    "    def __call__(self, predictions, labels):\n",
    "        # Flatten\n",
    "        labels = labels.view(-1)\n",
    "        \n",
    "        predictions = predictions.view(labels.shape[0], -1)\n",
    "\n",
    "        \n",
    "        # MRR computation\n",
    "        label_scores = predictions.gather(-1, labels.unsqueeze(-1))\n",
    "        rank = predictions.ge(label_scores).sum(1).float()\n",
    "        # print(rank)\n",
    "        reciprocal_rank = 1 / rank\n",
    "        self._sum += (reciprocal_rank).sum().item()\n",
    "        self._n += len(labels)\n",
    "\n",
    "    def get_metric(self, reset=False):\n",
    "        mrr = self._sum / (self._n + 1e-13)\n",
    "        if reset:\n",
    "            self.reset()\n",
    "        return mrr\n",
    "    def reset(self):\n",
    "        self._sum = 0.0\n",
    "        self._n = 0.0\n",
    "class Hits:\n",
    "    def __init__(self, topn):\n",
    "        self.topn = topn\n",
    "        self._sum = 0.0\n",
    "        self._n = 0.0\n",
    "\n",
    "    def __call__(self, predictions, labels):\n",
    "        # Flatten\n",
    "        labels = labels.view(-1)\n",
    "\n",
    "        predictions = predictions.view(labels.shape[0], -1)\n",
    "\n",
    "\n",
    "        # MRR computation\n",
    "        label_scores = predictions.gather(-1, labels.unsqueeze(-1))\n",
    "        rank = predictions.ge(label_scores).sum(1).float()\n",
    "        # reciprocal_rank = 1 / rank\n",
    "        score = rank.le(self.topn).float()\n",
    "        self._sum += (score).sum().item()\n",
    "        self._n += len(labels)\n",
    "\n",
    "    def get_metric(self, reset=False):\n",
    "        hits = self._sum / (self._n + 1e-13)\n",
    "        if reset:\n",
    "            self.reset()\n",
    "        return hits\n",
    "\n",
    "    def reset(self):\n",
    "        self._sum = 0.0\n",
    "        self._n = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [15:02<00:00, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027998542261428207\n",
      "0.058398392208394524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "sample_num = 6\n",
    "\n",
    "f = open(\"generated.txt\", 'w')\n",
    "mrr = MeanReciprocalRank()\n",
    "hits = Hits(50)\n",
    "total_ranks = []\n",
    "for _ in tqdm(range(10000)):\n",
    "    sample_ids = random.sample(range(len(s_list)), sample_num)\n",
    "    sample = \"\"\n",
    "    place_final = \"\"\n",
    "    for i, sample_id in enumerate(sample_ids):\n",
    "        sentence, place = s_list[sample_id].split('\\t')\n",
    "        words, len_place = sentence.split(), len(place.split())\n",
    "        if i == sample_num-1:\n",
    "            place_final = place\n",
    "            sentence = \"{})\".format(i+1) + \" \".join(words[:-1-len_place])\n",
    "        else:\n",
    "            sentence = \"{})\".format(i+1) + \" \".join(words) + '\\n'\n",
    "        sample += sentence\n",
    "    # input_ids = len(tokenizer.tokenize(sample))\n",
    "    # generated_text = generator(sample, do_sample=True, max_length=input_ids+5)[0][\"generated_text\"]\n",
    "    input_ids = tokenizer(sample, return_tensors=\"pt\").input_ids\n",
    "    input_ids = input_ids.to(device)\n",
    "\n",
    "    place_ids = tokenizer(place_final, return_tensors=\"pt\").input_ids\n",
    "    place_ids = place_ids.to(device)\n",
    "    max_new_tokens = place_ids.shape[1]\n",
    "\n",
    "\n",
    "    gen_output = model.generate(\n",
    "    input_ids,\n",
    "    # do_sample=True,\n",
    "    # temperature=0.9,\n",
    "    max_new_tokens = max_new_tokens,\n",
    "    # max_length = 100,\n",
    "    return_dict_in_generate = True,\n",
    "    output_scores = True,\n",
    "    pad_token_id = model.config.eos_token_id\n",
    ")\n",
    "    gen_tokens = gen_output.sequences\n",
    "    gen_scores = gen_output.scores\n",
    "    gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
    "    print(gen_text, file = f)\n",
    "    print(place_final, file = f)\n",
    "    \n",
    "    gen_scores = torch.stack(list(gen_scores), dim=0).squeeze(1)\n",
    "\n",
    "    mrr(gen_scores, place_ids)\n",
    "    \n",
    "    \n",
    "    hits(gen_scores, place_ids)\n",
    "    \n",
    "\n",
    "    ranks = torch.argsort(gen_scores, dim = 1, descending=True)\n",
    "    ranks = torch.argsort(ranks, dim = 1)\n",
    "    gen_ranks = [ranks[i][id].item() for i, id in enumerate(place_ids[0])]\n",
    "    total_ranks += gen_ranks\n",
    "    gen_ranks = list(map(str, gen_ranks))\n",
    "    gen_ranks = \",\".join(gen_ranks)\n",
    "    print(gen_ranks, file = f)\n",
    "\n",
    "f.close()\n",
    "print(mrr.get_metric())\n",
    "print(hits.get_metric())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25874"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.rubberband_canvas.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(total_ranks, bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 968, 1971, 2254], device='cuda:7')\n",
      "tensor([[ 2484, 36955,   634]], device='cuda:7')\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(gen_scores, dim = 1))\n",
    "print(place_ids)\n",
    "rank = torch.argsort(gen_scores, dim = 1, descending=True)\n",
    "rank = torch.argsort(rank, dim = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9842, 20013, 823]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[rank[i][id].item() for i, id in enumerate(place_ids[0])]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24e9b4ec3e5982e03e8718a00cb72022c31e89c1f9528f16f13627f3d4028efa"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
